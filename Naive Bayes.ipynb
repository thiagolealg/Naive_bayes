{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução aos Métodos Probabilísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Contextualização: O que são métodos probabilísticos e onde são aplicados?\n",
    "Métodos probabilísticos são técnicas matemáticas e estatísticas utilizadas para modelar, analisar e prever eventos que são incertos ou aleatórios. Ao contrário dos métodos determinísticos, que fornecem resultados exatos para um conjunto de entradas específico, os métodos probabilísticos lidam com a incerteza e fornecem uma gama de possíveis resultados com diferentes probabilidades associadas.\n",
    "\n",
    "Esses métodos são aplicados em uma ampla variedade de campos, incluindo:\n",
    "- **Finanças**: Para prever a movimentação de preços de ações ou modelar o risco em portfólios de investimento.\n",
    "- **Engenharia**: No projeto de sistemas que devem operar sob incertezas, como sistemas de comunicação ou sistemas de energia.\n",
    "- **Ciência**: Na modelagem de experimentos onde o resultado é incerto ou na análise de dados experimentais.\n",
    "- **Medicina**: Para prever a progressão de doenças ou a eficácia de um tratamento.\n",
    "- **Inteligência Artificial e Aprendizado de Máquina**: Para modelar a incerteza em previsões e tomada de decisões.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação: Naive Bayes vs. Redes Neurais\n",
    "\n",
    "### Naive Bayes\n",
    "- **Base probabilística**: \n",
    "  - O Naive Bayes é fundamentalmente um algoritmo probabilístico. Utiliza o Teorema de Bayes para calcular as probabilidades condicionais.\n",
    "  \n",
    "- **Suposições**:\n",
    "  - Uma suposição chave do Naive Bayes é que os atributos são condicionalmente independentes entre si, dada a classe. Isso é muitas vezes uma suposição \"ingênua\", daí o nome.\n",
    "  \n",
    "- **Complexidade e desempenho**:\n",
    "  - Em geral, o Naive Bayes é mais simples e rápido. Ideal para conjuntos de dados de alta dimensionalidade.\n",
    "\n",
    "### Redes Neurais\n",
    "- **Base probabilística**:\n",
    "  - Redes Neurais, por outro lado, não são fundamentalmente métodos probabilísticos como o Naive Bayes, mas certos aspectos, como a função de ativação softmax, têm interpretações probabilísticas.\n",
    "  \n",
    "- **Arquitetura e Mecanismo**:\n",
    "  - São compostas por camadas de neurônios. Esses neurônios são ajustados para aprender representações dos dados e as relações entre os atributos.\n",
    "  \n",
    "- **Suposições**:\n",
    "  - Redes Neurais não partem da suposição de independência dos atributos. Podem modelar interações complexas entre atributos.\n",
    "  \n",
    "- **Complexidade e desempenho**:\n",
    "  - São modelos mais complexos, muitas vezes necessitam de mais dados para treinamento e mais tempo computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.2. Diferença entre métodos determinísticos e probabilísticos\n",
    "A principal diferença entre os métodos determinísticos e probabilísticos reside em como eles lidam com a incerteza.\n",
    "\n",
    "**Métodos Determinísticos**: \n",
    "- Produzem um único resultado ou solução para um conjunto específico de entradas.\n",
    "- Baseiam-se na premissa de que o sistema ou problema é completamente conhecido e que não há incerteza.\n",
    "\n",
    "**Métodos Probabilísticos**:\n",
    "- Fornecem uma gama de possíveis soluções ou resultados, cada um com uma probabilidade associada.\n",
    "- São usados quando há incerteza no sistema ou problema, seja devido à falta de conhecimento, variação inerente ou ambos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.3. Importância dos métodos probabilísticos em cenários incertos\n",
    "Em muitos cenários do mundo real, a incerteza é uma característica inerente. Em tais situações, confiar apenas em métodos determinísticos pode levar a conclusões imprecisas ou decisões subótimas. Os métodos probabilísticos, ao reconhecerem e incorporarem essa incerteza, permitem uma modelagem e análise mais robusta.\n",
    "\n",
    "A importância dos métodos probabilísticos em cenários incertos inclui:\n",
    "- **Tomada de Decisão Informada**: Ao fornecer uma gama de possíveis resultados com probabilidades associadas, os decisores podem avaliar os riscos e benefícios de diferentes ações.\n",
    "- **Robustez em Previsões**: Em vez de uma única previsão pontual, os métodos probabilísticos oferecem uma distribuição de possíveis resultados.\n",
    "- **Otimização sob Incerteza**: Em problemas de otimização, os métodos probabilísticos podem ajudar a encontrar soluções que são robustas a variações ou incertezas no sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Teoria de Probabilidade Básica (revisão rápida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Conceito de Probabilidade\n",
    "\n",
    "Probabilidade é a maneira de expressarmos matematicamente quão provável é a ocorrência de um determinado evento. Podemos pensar nisso como uma forma de medir as chances de algo acontecer. \n",
    "\n",
    "- **Impossível**: O evento nunca acontecerá (Probabilidade = 0).\n",
    "- **Certo**: O evento certamente acontecerá (Probabilidade = 1).\n",
    "\n",
    "A fórmula para calcular a probabilidade de um evento A é:\n",
    "\n",
    "P(A) = número de maneiras que A pode ocorrer / número total de possíveis ocorrências\n",
    "\n",
    "**Exemplo**: Pense em jogar um dado comum, que tem lados numerados de 1 a 6. A chance, ou probabilidade, de jogarmos o dado e obtermos o número 3 é de 1 em 6. Escrevendo isso como uma fração, temos:\n",
    "\n",
    "P(3) = 1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Teorema de Bayes\n",
    "\n",
    "O Teorema de Bayes nos permite encontrar a probabilidade de um evento ocorrer, com base em novas evidências. É uma forma de combinar nosso conhecimento prévio (o que já sabemos) com novas informações (dados novos) para obter uma visão mais precisa da realidade.\n",
    "\n",
    "A fórmula do Teorema de Bayes é:\n",
    "\n",
    "P(A|B) = (P(B|A) x P(A)) / P(B)\n",
    "\n",
    "Onde:\n",
    "\n",
    "- P(A|B) é nossa nova visão sobre a probabilidade de A acontecer, dado que B ocorreu.\n",
    "- P(B|A) é a chance de B acontecer, assumindo que A ocorreu.\n",
    "- P(A) é a probabilidade original de A ocorrer (antes de sabermos sobre B).\n",
    "- P(B) é a chance total de B acontecer.\n",
    "\n",
    "Com o Teorema de Bayes, podemos refinar nossa compreensão sobre as chances de algo acontecer com base nas novas informações que recebemos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Eventos independentes e dependência condicional\n",
    "\n",
    "**Eventos independentes**:\n",
    "- Dois eventos A e B são considerados independentes se a ocorrência de um não afeta a ocorrência do outro. Matematicamente, isso é expresso como \"P de A intersecção B\"  P(A ∩ B) = P(A) × P(B).\n",
    "\n",
    "**Exemplo**: Jogar um dado duas vezes. O resultado do primeiro lançamento não afeta o resultado do segundo lançamento.\n",
    "\n",
    "**Dependência condicional**:\n",
    "- A probabilidade de um evento A dado que um evento B já ocorreu é chamada de probabilidade condicional e é denotada por \"P de A dado B\"\" P(A|B). Se A e B são independentes, então P(A|B) = P(A). Caso contrário, a dependência condicional existe.\n",
    "\n",
    "**Exemplo**: A probabilidade de alguém comprar um guarda-chuva, dado que está chovendo, é maior do que a probabilidade de comprar um guarda-chuva sem tal condição.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Introdução ao Algoritmo Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.1. Origens e princípio do algoritmo\n",
    "O algoritmo Naive Bayes é baseado no Teorema de Bayes, uma fórmula matemática que descreve como atualizar probabilidades com novas evidências. O algoritmo foi nomeado em homenagem ao reverendo Thomas Bayes, que forneceu a primeira fórmula para inferir a probabilidade de um evento A, dado o conhecimento prévio de eventos que podem estar relacionados a A.\n",
    "\n",
    "O princípio fundamental do Naive Bayes é usar a probabilidade de características (ou atributos) observadas em dados para fazer previsões ou classificações. Por exemplo, se quisermos prever se um e-mail é spam ou não, poderíamos usar a frequência de certas palavras no e-mail para fazer essa previsão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2. A suposição \"Naive\": Por que é \"ingênuo\"?\n",
    "A característica \"ingênua\" do Naive Bayes refere-se à suposição fundamental de que cada característica (ou atributo) é independente das outras. Isso significa que a presença (ou ausência) de uma característica não afeta a presença (ou ausência) de qualquer outra. \n",
    "\n",
    "Esta é uma suposição bastante forte e muitas vezes não reflete a realidade dos dados. No entanto, apesar desta suposição simplista, o Naive Bayes muitas vezes funciona surpreendentemente bem em muitas aplicações práticas, especialmente quando a dimensionalidade dos dados é alta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.3. Aplicações práticas do Naive Bayes\n",
    "O Naive Bayes é usado em uma variedade de aplicações, incluindo:\n",
    "\n",
    "- **Classificação de texto**: Como classificar e-mails como spam ou não spam, categorização de notícias, análise de sentimento, etc.\n",
    "- **Reconhecimento de padrões**: Na detecção de rostos em imagens, por exemplo.\n",
    "- **Sistemas de recomendação**: Para recomendar produtos ou serviços com base em características de uso.\n",
    "- **Diagnóstico médico**: Para diagnosticar doenças com base em sintomas.\n",
    "\n",
    "A simplicidade e eficiência do Naive Bayes o tornam adequado para conjuntos de dados de alta dimensão e situações onde a velocidade é uma preocupação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('flores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados em X (atributos) e y (classe alvo)\n",
    "X = df.drop(columns=['species'])\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização de Dados no Algoritmo Naive Bayes\n",
    "\n",
    "A aplicação da normalização em algoritmos de aprendizado de máquina é um tópico importante e, no caso do Naive Bayes, depende da variação específica que você está usando.\n",
    "\n",
    "## Gaussian Naive Bayes\n",
    "### Características:\n",
    "- **Aplicação:** Comumente usado para características contínuas.\n",
    "- **Suposição:** Assume que os dados para cada classe seguem uma distribuição normal.\n",
    "\n",
    "### Normalização:\n",
    "- **Necessidade:** É geralmente uma boa prática normalizar os dados para torná-los mais próximos de uma distribuição normal.\n",
    "- **Método Sugerido:** StandardScaler, pois transforma os dados para ter média 0 e desvio padrão 1.\n",
    "\n",
    "## Multinomial Naive Bayes e Bernoulli Naive Bayes\n",
    "\n",
    "### Características:\n",
    "- **Aplicação Multinomial NB:** Comumente usado para contagens ou características discretas, como contagem de palavras em classificação de texto.\n",
    "- **Aplicação Bernoulli NB:** Usado para características binárias.\n",
    "\n",
    "### Normalização:\n",
    "- **Necessidade para Multinomial NB:** Não é essencial, mas é importante garantir que todos os valores sejam não-negativos.\n",
    "- **Método Sugerido para Multinomial NB:** MinMaxScaler para garantir que os valores sejam não-negativos.\n",
    "- **Necessidade para Bernoulli NB:** Certificar-se de que as características são binárias (0 ou 1).\n",
    "\n",
    "## Impacto do Scaling:\n",
    "- **Impacto Geral:** Muitos algoritmos de machine learning são sensíveis à escala das características.\n",
    "- **Especificidade do Naive Bayes:** As probabilidades são baseadas na distribuição dos dados. Se os dados forem dimensionados, as probabilidades calculadas mudarão, mas as decisões de classificação geralmente permanecerão as mesmas.\n",
    "  \n",
    "## Conclusão:\n",
    "- Para **Gaussian NB**, é uma boa prática normalizar os dados.\n",
    "- Para **Multinomial e Bernoulli NB**, garantir que os dados estejam no formato correto é mais importante do que a normalização em si.\n",
    "- **Finalidade da Normalização:** Pode não afetar diretamente a decisão de classificação, mas ajuda em termos de convergência e estabilidade numérica, especialmente quando outros algoritmos são usados em conjunto ou durante o treinamento com métodos de otimização iterativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o normalizador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# A função fit_transform calcula a média e o desvio padrão dos dados de treinamento \n",
    "# e então usa esses valores para normalizá-los. \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# A função transform usa a média e o desvio padrão previamente computados com fit_transform\n",
    "# no conjunto de treinamento para normalizar o conjunto de teste.\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa uma instância do modelo\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Treinando o modelo Naive Bayes\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Realiza previs~oes com o modelo treinado\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotando a Matriz de Confusão com heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4) # para definir o tamanho da fonte\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, cmap='Blues', fmt='g') # 'fmt' evita números científicos na matriz\n",
    "plt.ylabel('Valores Verdadeiros')\n",
    "plt.xlabel('Predições')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# Imprimindo métricas relevantes\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Detalhamento do Algoritmo Naive Bayes\n",
    "\n",
    "## 4.1. Probabilidade a priori, probabilidade a posteriori, verossimilhança e evidência\n",
    "\n",
    "- **Probabilidade a priori (Prior Probability, P(A))**: É a probabilidade inicial ou intrínseca de um evento ocorrer, sem levar em conta qualquer evidência adicional. Por exemplo, em um problema de classificação, a probabilidade a priori pode ser a proporção geral de cada classe no conjunto de dados.\n",
    "\n",
    "- **Probabilidade a posteriori (Posterior Probability, P(A|B))**: É a probabilidade revisada de um evento A ocorrer, levando em conta uma nova evidência B. No contexto do Naive Bayes, refere-se à probabilidade de uma instância pertencer a uma determinada classe, dadas suas características.\n",
    "\n",
    "- **Verossimilhança (Likelihood, P(B|A))**: Descreve a probabilidade de observar a evidência (B) dado que um evento (A) ocorreu. No Naive Bayes, é a probabilidade das características de uma instância, dada sua classe.\n",
    "\n",
    "- **Evidência (Evidence, P(B))**: É a probabilidade geral da evidência (sem levar em consideração a classe). No contexto do Naive Bayes, geralmente é calculada como a soma das verossimilhanças ponderadas pelas probabilidades a priori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Formulação Matemática do Naive Bayes\n",
    "\n",
    "A base para o algoritmo Naive Bayes é o Teorema de Bayes. A fórmula para este teorema, no contexto do algoritmo, é:\n",
    "\n",
    "\\[ P(y|X) = \\frac{P(X|y) \\times P(y)}{P(X)} \\]\n",
    "\n",
    "### Explicação dos Termos:\n",
    "- **P(y|X)**: Esta é a probabilidade posterior da classe 'y' dado o vetor de características 'X'.\n",
    "- **P(X|y)**: Conhecida como verossimilhança, representa a probabilidade do vetor 'X' sendo observado, dado que a classe é 'y'.\n",
    "- **P(y)**: Representa a probabilidade a priori da classe 'y'. Em outras palavras, a probabilidade geral ou inicial de 'y' independentemente das características.\n",
    "- **P(X)**: Esta é a probabilidade do vetor de características 'X'. Também conhecido como evidência.\n",
    "\n",
    "Dado que o Naive Bayes opera sob uma suposição de independência, a verossimilhança, \\( P(X|y) \\), é calculada como o produto das probabilidades individuais de cada característica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3. Cálculo das Probabilidades usando Máxima Verossimilhança\n",
    "\n",
    "Quando se trata de calcular as probabilidades para o Naive Bayes, uma abordagem comum é utilizar o método de máxima verossimilhança (ou MLE, do inglês Maximum Likelihood Estimation).\n",
    "\n",
    "### O que é MLE?\n",
    "MLE é uma técnica estatística usada para estimar os parâmetros de um modelo. No caso do Naive Bayes, é empregado para estimar a verossimilhança, \\( P(X|y) \\).\n",
    "\n",
    "### Como funciona?\n",
    "Para cada característica presente no dataset, a probabilidade dessa característica ocorrer para uma determinada classe é calculada. O MLE, basicamente, ajusta os parâmetros de modo que a probabilidade observada dos dados (dada a parametrização) seja maximizada.\n",
    "\n",
    "### Aplicação no Naive Bayes:\n",
    "Em situações práticas, especialmente quando lidamos com características discretas, o MLE pode ser calculado como a proporção da ocorrência de uma característica para uma classe específica em relação ao total de observações daquela classe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.4. Estimativa a Posteriori Máxima (MAP)\n",
    "\n",
    "A Estimativa a Posteriori Máxima é uma alternativa ao MLE para calcular as probabilidades em modelos estatísticos, incluindo o Naive Bayes. \n",
    "\n",
    "### Diferença entre MLE e MAP:\n",
    "\n",
    "- **MLE**: Foca na maximização da verossimilhança dos dados observados. Não leva em consideração qualquer informação a priori (ou pré-existente) sobre os parâmetros que está tentando estimar.\n",
    "  \n",
    "- **MAP**: Combina a verossimilhança dos dados observados (como no MLE) com uma distribuição a priori sobre os parâmetros. O objetivo é encontrar os parâmetros que maximizem a probabilidade posterior.\n",
    "\n",
    "### Como funciona no Naive Bayes?\n",
    "\n",
    "- Em Naive Bayes, quando estimamos a probabilidade de uma característica dada uma classe, podemos incorporar um \"prior\" (informação prévia) sobre essa probabilidade. Isso é especialmente útil quando os dados são escassos ou para evitar o problema de probabilidade zero (por exemplo, se uma característica nunca ocorreu com uma determinada classe nos dados de treinamento).\n",
    "\n",
    "- Em termos práticos, isso é frequentemente feito através de uma técnica chamada **\"suavização de Laplace\"** ou **\"add-one smoothing\"**. O princípio básico é adicionar uma pequena quantidade (como 1) ao numerador e ao denominador ao calcular as probabilidades. Isso garante que nenhuma probabilidade seja exatamente zero, o que pode ser problemático em cálculos posteriores.\n",
    "\n",
    "### Benefícios do MAP no Naive Bayes:\n",
    "\n",
    "1. **Evita Probabilidades Zero**: Como mencionado, evita o cenário onde uma característica que nunca foi observada em treinamento leva a uma probabilidade zero na classificação.\n",
    "  \n",
    "2. **Incorpora Informação a Priori**: Se houver algum conhecimento prévio sobre as probabilidades das características, ele pode ser incorporado no cálculo usando MAP.\n",
    "\n",
    "3. **Robustez com Dados Escassos**: Em situações onde os dados de treinamento são limitados, a suavização pode ajudar a fazer estimativas mais robustas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraud_detection_bank_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isna().sum()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isna().sum()).values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.targets.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes e Classes Desbalanceadas na Classificação\n",
    "\n",
    "### 1. O que são Classes Desbalanceadas?\n",
    "- Classes desbalanceadas ocorrem quando uma categoria (ou classe) em um conjunto de dados tem muito mais amostras em comparação com outra(s).\n",
    "- Por exemplo, em um conjunto de dados sobre detecção de fraude, a maioria das transações é legítima (classe majoritária) enquanto apenas uma pequena porcentagem é fraudulenta (classe minoritária).\n",
    "\n",
    "### 2. Problemas com Classes Desbalanceadas\n",
    "- Modelos treinados em dados desbalanceados podem apresentar um desempenho enviesado, favorecendo frequentemente a classe majoritária.\n",
    "- A métrica de acurácia pode ser enganosamente alta, já que prever sempre a classe majoritária pode ainda resultar em uma alta taxa de acertos.\n",
    "\n",
    "### 3. Naive Bayes e o Desbalanceamento\n",
    "- **Probabilidade a Priori (P(y))**: \n",
    "  - No Naive Bayes, a probabilidade a priori de cada classe é calculada com base na frequência relativa dos dados de treinamento.\n",
    "  - Em um conjunto de dados desbalanceado, a classe majoritária terá uma probabilidade a priori mais alta, o que pode inclinar o modelo em sua direção.\n",
    "  \n",
    "- **Influência na Classificação**: \n",
    "  - A probabilidade a posteriori (resultado do Naive Bayes) pode ser enviesada pela alta probabilidade a priori da classe majoritária.\n",
    "  - Isso pode levar a uma tendência na predição da classe majoritária, mesmo quando algumas características são mais indicativas da classe minoritária.\n",
    "\n",
    "### 4. Soluções para o Desbalanceamento com Naive Bayes\n",
    "- **Reamostragem**: Inclui técnicas como oversampling (aumentar a quantidade de exemplos da classe minoritária) e undersampling (reduzir a quantidade de exemplos da classe majoritária).\n",
    "- **Utilizar Métricas Adequadas**: Evitar confiar apenas na acurácia. Utilizar outras métricas como precisão, recall, F1-score, especialmente para a classe minoritária.\n",
    "- **Modificar Pesos das Classes**: Algumas implementações mais complexas do Naive Bayes permitem que se atribuam pesos diferentes para as classes, compensando o desbalanceamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha do Algoritmo Naive Bayes e Normalização\n",
    "\n",
    "Dado o problema em mãos, onde temos características numéricas contínuas como 'glucose no sangue' e 'bloodpressure', o **Gaussian Naive Bayes** é a escolha mais apropriada. Isto porque:\n",
    "- **GaussianNB**: É adequado para características contínuas, pois assume que os dados seguem uma distribuição normal (gaussiana) para cada classe.\n",
    "\n",
    "Quanto à normalização, a opção escolhida é a **StandardScaler**:\n",
    "- A GaussianNB assume que os dados seguem uma distribuição normal. Usando o `StandardScaler`, transformamos os dados para ter média 0 e desvio padrão 1, tornando-os mais próximos de uma distribuição normal.\n",
    "\n",
    "### Escolha da Técnica de Estimativa\n",
    "\n",
    "- **Máxima Verossimilhança (MLE)**: É o método padrão para estimar as probabilidades. Adequado quando temos uma quantidade razoável de dados.\n",
    "  \n",
    "- **Estimativa a Posteriori Máxima (MAP)**: Incorpora uma informação prévia (prior) sobre as probabilidades. Útil quando os dados são escassos ou para evitar o problema de probabilidade zero.\n",
    "\n",
    "Vamos aplicar ambos os métodos para comparar os resultados na prática.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar os dados em X (atributos) e y (classe alvo)\n",
    "X = df.drop(columns=['targets'])\n",
    "y = df['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização usando StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento com GaussianNB (usando MLE)\n",
    "gnb_mle = GaussianNB()\n",
    "gnb_mle.fit(X_train, y_train)\n",
    "y_pred_mle = gnb_mle.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento com GaussianNB com suavização (simulando MAP)\n",
    "gnb_map = GaussianNB(var_smoothing=0.1)  # valor pequeno para suavização\n",
    "gnb_map.fit(X_train, y_train)\n",
    "y_pred_map = gnb_map.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred_mle)\n",
    "\n",
    "# Plotando a Matriz de Confusão com heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4) # para definir o tamanho da fonte\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, cmap='Blues', fmt='g') # 'fmt' evita números científicos na matriz\n",
    "plt.ylabel('Valores Verdadeiros')\n",
    "plt.xlabel('Predições')\n",
    "plt.title('Matriz de Confusão MLE')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelatório de Classificação (usando Máxima Verossimilhança):\\n\", classification_report(y_test, y_pred_mle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred_map)\n",
    "\n",
    "# Plotando a Matriz de Confusão com heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4) # para definir o tamanho da fonte\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, cmap='Blues', fmt='g') # 'fmt' evita números científicos na matriz\n",
    "plt.ylabel('Valores Verdadeiros')\n",
    "plt.xlabel('Predições')\n",
    "plt.title('Matriz de Confusão MAP')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelatório de Classificação (usando Estimativa a Posteriori Máxima):\\n\", classification_report(y_test, y_pred_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Avaliação de Modelos de Classificação\n",
    "\n",
    "#### 1. Matriz de Confusão\n",
    "\n",
    "A matriz de confusão é uma tabela usada para descrever o desempenho de um modelo de classificação.\n",
    "\n",
    "- **Verdadeiros Positivos (TP)**: Casos onde o modelo previu 1 e o verdadeiro valor também é 1.\n",
    "- **Verdadeiros Negativos (TN)**: Casos onde o modelo previu 0 e o verdadeiro valor também é 0.\n",
    "- **Falsos Positivos (FP)**: Casos onde o modelo previu 1, mas o verdadeiro valor é 0. Também conhecidos como \"erro tipo I\".\n",
    "- **Falsos Negativos (FN)**: Casos onde o modelo previu 0, mas o verdadeiro valor é 1. Também conhecidos como \"erro tipo II\".\n",
    "\n",
    "#### 2. Precisão (Precision)\n",
    "\n",
    "A precisão mede a proporção de identificações positivas feitas corretamente.\n",
    "\n",
    "Formula: Precisão = TP / (TP + FP)\n",
    "\n",
    "#### 3. Revocação (Recall)\n",
    "\n",
    "A revocação, ou sensibilidade, indica a proporção de positivos reais que foram identificados corretamente.\n",
    "\n",
    "Formula: Recall = TP / (TP + FN)\n",
    "\n",
    "#### 4. F1-Score\n",
    "\n",
    "O F1-Score é a média harmônica entre precisão e revocação, buscando um equilíbrio entre as duas métricas.\n",
    "\n",
    "Formula: F1-Score = 2 * (Precisão * Recall) / (Precisão + Recall)\n",
    "\n",
    "#### 5. Suporte (Support)\n",
    "\n",
    "O suporte é o número de ocorrências reais da classe no conjunto de dados. Ele mostra quantas amostras no conjunto de teste têm essa classe como label verdadeiro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Variações do Algoritmo Naive Bayes\n",
    "\n",
    "O algoritmo Naive Bayes é uma técnica de classificação baseada no teorema de Bayes. Existem várias variações do Naive Bayes, adaptadas para diferentes tipos de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5.1. Gaussian Naive Bayes\n",
    "\n",
    "Este é o tipo mais comum de Naive Bayes usado quando os recursos (features) têm valores contínuos.\n",
    "\n",
    "- **Características Principais**:\n",
    "  - Assume que os recursos seguem uma distribuição normal ou gaussiana.\n",
    "  - A probabilidade de uma característica é calculada usando a fórmula da distribuição gaussiana.\n",
    "\n",
    "É especialmente adequado para problemas em que os recursos têm valores contínuos, como medidas em experimentos científicos ou valores em colunas de um conjunto de dados.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5.2. Multinomial Naive Bayes\n",
    "Esta variação é adequada para classificação com recursos discretos.\n",
    "\n",
    "- **Características Principais**:\n",
    "  - Frequentemente usado em problemas de classificação de texto, onde os recursos podem ser a contagem ou a presença/ausência de palavras em um documento.\n",
    "  - Assume que os recursos têm distribuição multinomial.\n",
    "\n",
    "Por exemplo, pode ser usado em sistemas de filtragem de spam para classificar e-mails como \"spam\" ou \"não spam\" com base na frequência de certas palavras.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5.3. Bernoulli Naive Bayes\n",
    "É uma variação do Naive Bayes adequada para dados binários.\n",
    "\n",
    "- **Características Principais**:\n",
    "  - Pode ser usado em problemas de classificação de texto onde os recursos são binários, ou seja, indicam a presença ou ausência de uma palavra.\n",
    "  - Assume que os recursos têm uma distribuição de Bernoulli.\n",
    "\n",
    "Um exemplo prático é a classificação de documentos com base na presença/ausência de palavras-chave específicas.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Prós e Contras do Naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 7.1. Vantagens do algoritmo\n",
    "\n",
    "1. **Simplicidade e rapidez:** O Naive Bayes é conhecido por ser um algoritmo rápido e fácil de construir, especialmente quando o conjunto de dados tem dimensões elevadas.\n",
    "\n",
    "2. **Requer menos dados:** O Naive Bayes não necessita de tantos dados para ser eficaz e, frequentemente, apresenta resultados decentes mesmo com conjuntos de dados relativamente pequenos.\n",
    "\n",
    "3. **Trata bem características irrelevantes:** Devido à sua suposição de independência, características irrelevantes não prejudicam o desempenho, pois sua contribuição é neutralizada.\n",
    "\n",
    "4. **Bom para classificação de texto:** Naive Bayes é notório por seu desempenho em problemas de classificação de texto, como filtragem de spam e análise de sentimento.\n",
    "\n",
    "5. **Trabalha bem com variáveis categóricas:** Não requer codificação adicional ou transformação para variáveis categóricas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7.2. Limitações do algoritmo\n",
    "\n",
    "1. **Suposição de independência:** O \"Naive\" em Naive Bayes refere-se à suposição ingênua de que todas as características são independentes entre si, o que raramente é verdade na prática.\n",
    "\n",
    "2. **Problema de probabilidade zero:** Se uma categoria não aparece no conjunto de treinamento, o algoritmo atribuirá uma probabilidade de zero e não poderá fazer uma previsão. Isso é conhecido como \"problema de probabilidade zero\". Soluções como o \"alisamento de Laplace\" são utilizadas para corrigir isso.\n",
    "\n",
    "3. **Modelo de alta polaridade:** Se uma característica está fortemente correlacionada com uma classe específica, isso pode polarizar o modelo, e ele pode falhar em cenários mais gerais.\n",
    "\n",
    "4. **Não é ideal para tarefas de regressão:** O Naive Bayes é primariamente um algoritmo de classificação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7.3. Quando usar e quando não usar Naive Bayes\n",
    "\n",
    "### Quando usar:\n",
    "1. **Classificação de texto:** Como mencionado anteriormente, Naive Bayes é uma escolha popular para tarefas como filtragem de spam e análise de sentimento.\n",
    "\n",
    "2. **Conjuntos de dados com muitas características:** Devido à sua rapidez e simplicidade, Naive Bayes pode ser uma boa escolha quando se lida com conjuntos de dados de alta dimensão.\n",
    "\n",
    "3. **Prototipagem rápida:** Quando você quer um modelo rápido e bom o suficiente como uma solução temporária.\n",
    "\n",
    "4. **Conjuntos de dados com características categóricas:** O Naive Bayes trata naturalmente variáveis categóricas sem necessidade de codificação adicional.\n",
    "\n",
    "### Quando não usar:\n",
    "1. **Quando a inter-relação entre características é crucial:** Se as características não são independentes ou se a inter-relação entre elas é um fator crucial para a classificação.\n",
    "\n",
    "2. **Tarefas de regressão:** Naive Bayes não é adequado para tarefas onde o objetivo é prever um valor contínuo.\n",
    "\n",
    "3. **Quando o desempenho do modelo é crítico:** Em situações onde é necessário o melhor modelo possível, pode ser melhor considerar modelos mais sofisticados.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 8. Aplicações Práticas e Estudos de Caso\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 8.1. Naive Bayes em Detecção de Spam\n",
    "\n",
    "\n",
    "\n",
    "O algoritmo Naive Bayes é frequentemente usado na detecção de spam devido à sua eficácia e rapidez. O princípio por trás disso é simples: determinar a probabilidade de uma mensagem ser spam com base nas palavras presentes na mensagem.\n",
    "\n",
    "### Como funciona:\n",
    "\n",
    "1. **Treinamento do modelo:** O modelo é treinado em um conjunto de dados contendo mensagens classificadas como spam ou não spam. Durante esse processo, o algoritmo aprende a probabilidade de certas palavras aparecerem em mensagens de spam em comparação com mensagens não spam.\n",
    "\n",
    "2. **Classificação:** Para uma nova mensagem, o modelo calcula a probabilidade de ser spam com base na presença (ou ausência) de palavras. Se a probabilidade exceder um certo limiar, a mensagem é classificada como spam.\n",
    "\n",
    "3. **Características a considerar:** Além das palavras, outros aspectos, como o endereço do remetente, a hora do envio ou a presença de anexos, também podem ser usados.\n",
    "\n",
    "### Exemplo prático:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.spam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separação dos dados em X (text) e y (spam)\n",
    "X = df['text']\n",
    "y = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Transformação dos textos em vetores numéricos\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Treinamento do modelo MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Realização de previsões com o conjunto de teste\n",
    "y_pred = mnb.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotando a Matriz de Confusão com heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4) # para definir o tamanho da fonte\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, cmap='Blues', fmt='g') # 'fmt' evita números científicos na matriz\n",
    "plt.ylabel('Valores Verdadeiros')\n",
    "plt.xlabel('Predições')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelatório de Classificação Classificação de Spam:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 8.2. Naive Bayes em Análise de Sentimentos\n",
    "\n",
    "\n",
    "\n",
    "A análise de sentimentos trata de compreender as emoções por trás das palavras, e o Naive Bayes é uma ferramenta popular para isso.\n",
    "\n",
    "### Como funciona:\n",
    "\n",
    "1. **Treinamento do modelo:** Semelhante à detecção de spam, o modelo é treinado em um conjunto de dados contendo declarações classificadas com base no sentimento que expressam (por exemplo, positivo, negativo, neutro).\n",
    "\n",
    "2. **Classificação:** Para uma nova declaração, o modelo calcula a probabilidade de pertencer a uma determinada classe de sentimento com base nas palavras presentes.\n",
    "\n",
    "3. **Importância da nuance:** Ao contrário da detecção de spam, a análise de sentimentos pode ser mais sutil. Uma palavra que é neutra em um contexto pode ser positiva ou negativa em outro. Por exemplo, \"longo\" em \"longo dia\" pode ter uma conotação negativa, enquanto em \"longa vida\" tem uma conotação positiva.\n",
    "\n",
    "### Exemplo prático:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Corona_NLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outra forma de Fazer\n",
    "# Define um dicionário para mapear os sentimentos para números\n",
    "sentiment_mapping = {\n",
    "    'Extremely Negative': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Extremely Positive': 4\n",
    "}\n",
    "\n",
    "# Use o método replace para aplicar o mapeamento\n",
    "df['Sentiment'] = df['Sentiment'].replace(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Como aprendemos\n",
    "df.loc[df['Sentiment'] == 'Extremely Negative', 'Sentiment'] = 0\n",
    "df.loc[df['Sentiment'] == 'Negative', 'Sentiment'] = 1\n",
    "df.loc[df['Sentiment'] == 'Neutral', 'Sentiment'] = 2\n",
    "df.loc[df['Sentiment'] == 'Positive', 'Sentiment'] = 3\n",
    "df.loc[df['Sentiment'] == 'Extremely Positive', 'Sentiment'] = 4\n",
    "df['Sentiment'] = df['Sentiment'].astype(int)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.OriginalTweet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separação dos dados em X (text) e y (spam)\n",
    "X = df['OriginalTweet']\n",
    "y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Divisão dos dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Transformação dos textos em vetores numéricos\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Treinamento do modelo MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Realização de previsões com o conjunto de teste\n",
    "y_pred = mnb.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotando a Matriz de Confusão com heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.set(font_scale=1.4) # para definir o tamanho da fonte\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16}, cmap='Blues', fmt='g') # 'fmt' evita números científicos na matriz\n",
    "plt.ylabel('Valores Verdadeiros')\n",
    "plt.xlabel('Predições')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRelatório de Classificação Classificação de Sentimentos:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1: Previsão de Diabetes usando Naive Bayes\n",
    "\n",
    "### Objetivo\n",
    "- Utilizar a base de dados `diabetes.csv` e o algoritmo Naive Bayes para prever se uma pessoa tem ou não diabetes.\n",
    "\n",
    "### Procedimentos\n",
    "\n",
    "#### 1.1. Leitura dos Dados\n",
    "- Leia o dataset `diabetes.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.2. Separação dos Dados\n",
    "- Separe os dados em:\n",
    "  - `X` representando os atributos (colunas: `glucose` e `bloodpressure`).\n",
    "  - `y` representando a classe alvo (coluna: `diabetes`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.3. Divisão dos Dados\n",
    "- Separe os dados em conjuntos de treinamento e teste, usando 85% dos dados para treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.4. Normalização\n",
    "- Normalize os dados de `X` de treinamento utilizando o `StandardScaler`.\n",
    "- Utilize o scaler já ajustado nos dados de treinamento para normalizar os dados de `X` de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.5. Treinamento do Modelo\n",
    "- Treine o modelo Naive Bayes utilizando o conjunto de treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.6. Avaliação do Modelo\n",
    "- Realize a previsão no X de teste.\n",
    "- Exiba a matriz de confusão.\n",
    "- Apresente as métricas de classificação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2: Previsão de Categorias de Produtos em E-commerce usando Naive Bayes\n",
    "\n",
    "### Descrição da Base de Dados:\n",
    "Este dataset de classificação baseado em E-commerce contém textos referentes a 4 categorias de produtos:\n",
    "- \"Eletrônicos\" (Electronics)\n",
    "- \"Itens Domésticos\" (Household)\n",
    "- \"Livros\" (Books)\n",
    "- \"Roupas e Acessórios\" (Clothing & Accessories)\n",
    "\n",
    "Estas categorias abrangem aproximadamente 80% dos produtos presentes em qualquer site de E-commerce.\n",
    "\n",
    "### Procedimentos:\n",
    "\n",
    "#### Objetivo:\n",
    "- Utilizar a base de dados `ecommerceDataset.csv` e o algoritmo Naive Bayes para prever a categoria de um produto.\n",
    "\n",
    "#### 2.1 Leitura e Separação dos Dados:\n",
    "- Leia o dataset `ecommerceDataset.csv`.\n",
    "- Separe os dados em:\n",
    "  - `X` representando os textos dos produtos.\n",
    "  - `y` representando a categoria dos produtos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.2 Divisão dos Dados:\n",
    "- Divida os dados em conjuntos de treinamento e teste, destinando 70% dos dados para o treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.3 Processamento de Textos:\n",
    "- Utilize a biblioteca `CountVectorizer` para transformar os textos em vetores numéricos.\n",
    "  - Aplique `fit_transform` nos dados de treinamento.\n",
    "  - Use `transform` nos dados de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.4 Treinamento e Previsão:\n",
    "- Treine o modelo Naive Bayes com o conjunto de treinamento.\n",
    "- Realize previsões com o modelo treinado usando os dados de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.5 Avaliação do Modelo:\n",
    "- Exiba a matriz de confusão.\n",
    "- Mostre as métricas de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desenvolva a resposta neste bloco de código\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
